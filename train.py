import argparse
import tensorflow as tf
from tensorflow.keras.callbacks import ModelCheckpoint

import wandb

from dataloader import FrameGenerator
from wandb_utils import init_wandb
from custom_rnn import CustomRNN

parser = argparse.ArgumentParser(description='DNN curve training')
parser.add_argument('--seed', type=int, default=1,
                    help='The seed.')
parser.set_defaults(use_wandb=False)
parser.add_argument('--no_wandb', action='store_false', dest='use_wandb',
                    help='Turns off logging to wandb')
parser.add_argument('--sequence_length', type=int, default=10,
                    help='The sequence length.')
parser.add_argument('--num_res_blocks', type=int, default=16,
                    help='Number of residual blocks.')
parser.add_argument('--num_filters', type=int, default=64,
                    help='The sequence length.')
parser.add_argument('--kernel_size', type=int, default=3,
                    help='Kernel size.')
parser.add_argument('--strides', type=int, default=1,
                    help='Strides.')
parser.add_argument('--padding', type=str, default='same',
                    help='Padding.')
parser.add_argument('--block_size', type=int, default=4,
                    help='Block size for upsampling.')
parser.add_argument('--lr_height', type=int, default=32,
                    help='Height of LR image.')
parser.add_argument('--lr_width', type=int, default=32,
                    help='Width of LR image.')
parser.add_argument('--hr_height', type=int, default=128,
                    help='Height of HR image.')
parser.add_argument('--hr_width', type=int, default=128,
                    help='Width of HR image.')
parser.add_argument('--ground_truth_train_dir', type=str, default='./data/train/',
                    help='Directory with ground truth training data.')
parser.add_argument('--ground_truth_val_dir', type=str, default='./data/val/',
                    help='Directory with ground truth validation data.')
parser.add_argument('--tecogan_generated_train_dir', type=str, default='./data/train/',
                    help='Directory with HR training images generated by TecoGAN.')
parser.add_argument('--tecogan_generated_val_dir', type=str, default='./data/val/',
                    help='Directory with HR validation images generated by TecoGAN.')
parser.add_argument('--alpha', type=float, default=1,
                    help='Weighting parameter for distillation loss.') # TODO Check default value for alpha


if __name__ == "__main__":
    args = parser.parse_args()
    init_wandb(args)

    custom_model = CustomRNN(args)
    model = custom_model.get_model()
    
    
    output_signature = (tf.TensorSpec(shape=(None, args.sequence_length, args.lr_height, args.lr_width, 3), dtype=tf.float32),
                        (tf.TensorSpec(shape=(None, args.sequence_length, args.hr_height, args.hr_width, 3), dtype=tf.float32),
                        tf.TensorSpec(shape=(None, args.sequence_length, args.hr_height, args.hr_width, 3), dtype=tf.float32)))

    train_ds = tf.data.Dataset.from_generator(FrameGenerator(args.ground_truth_train_dir, args.tecogan_generated_train_dir, args.sequence_length, output_size = (args.lr_height, args.lr_width), training=True),
                                              output_signature=output_signature)
    val_ds = tf.data.Dataset.from_generator(FrameGenerator(args.ground_truth_val_dir, args.tecogan_generated_val_dir, args.sequence_length, output_size = (args.lr_height, args.lr_width), training=False),
                                            output_signature=output_signature)
    AUTOTUNE = tf.data.AUTOTUNE

    # train_ds = train_ds.cache().shuffle(300).prefetch(buffer_size=AUTOTUNE)
    # val_ds = val_ds.cache().shuffle(300).prefetch(buffer_size=AUTOTUNE)

    print(train_ds)

    model.compile(optimizer='adam',
                  loss=custom_model.model_loss)

    model.fit(train_ds,
              epochs=10,
              validation_data=val_ds,
              callbacks=ModelCheckpoint(filepath = './checkpoints/'))